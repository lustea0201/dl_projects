{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input            1000 x 2 x 14 x 14   dtype               \n",
      "train_target                  1000          dtype               \n",
      "train_classes               1000 x 2        dtype               \n",
      "test_input             1000 x 2 x 14 x 14   dtype               \n",
      "test_target                   1000          dtype               \n",
      "test_classes                1000 x 2        dtype               \n"
     ]
    }
   ],
   "source": [
    "from dlc_practical_prologue import generate_pair_sets\n",
    "\n",
    "nSamples = 1000\n",
    "data = generate_pair_sets(nSamples)\n",
    "var_names = [\"train_input\", \"train_target\", \"train_classes\", \"test_input\", \"test_target\", \"test_classes\"]\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = data\n",
    "stringWidth = 20\n",
    "for i, el in enumerate(list(map(lambda x: (x.shape, x.dtype), data))):\n",
    "    print('{:s}  {:s}  {:s}'.format(\n",
    "        var_names[i].ljust(stringWidth),\n",
    "        ' x '.join(list(map(lambda x: str(x), list(el[0])))).center(stringWidth), \n",
    "        'dtype'.ljust(stringWidth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import show_pair\n",
    "\n",
    "show_pair(train_input, train_target, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without using the information from the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, h1, h2):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=2)\n",
    "        self.fc1 = nn.Linear(64, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.fc3 = nn.Linear(2*h2, 1)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        \n",
    "    def element_forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.fc1(x.view(-1, 64)))\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x \n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = x[:, 0, :, :].unsqueeze(axis = 1)\n",
    "        x2 = x[:, 1, :, :].unsqueeze(axis = 1)\n",
    "        \n",
    "    \n",
    "        x1 = self.element_forward(x1)\n",
    "        x2 = self.element_forward(x2)\n",
    "        \n",
    "        # I'd like to do (x1 <= x2).float().squeeze(), but then loss.backward() doesn't work\n",
    "        x = torch.cat([x1, x2], axis = 1)\n",
    "        x = self.fc3(x).squeeze()\n",
    "        \n",
    "        \n",
    "        return x\n",
    "    \n",
    "def accuracy(model, input_, target, mini_batch_size):\n",
    "    nb_errors = 0\n",
    "    for i in range(0, input_.size(0), mini_batch_size):\n",
    "        output = model(input_.narrow(0, i, mini_batch_size))\n",
    "        if output.isnan().sum():\n",
    "            print('NANS')\n",
    "            \n",
    "        pred = (output > 0).long()\n",
    "        gt = target.narrow(0, i, mini_batch_size)\n",
    "        nb_errors += (pred != gt).sum().item()\n",
    "    N = input_.shape[0]\n",
    "    return 100*(N-nb_errors)/N\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, train_input, train_target, mini_batch_size, optimizer, verbose = True):\n",
    "    for e in range(nb_epochs):\n",
    "        epoch_loss = 0\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            input_ = train_input.narrow(0, b, mini_batch_size)\n",
    "            output = model(input_)\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            model.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                    \n",
    "        train_acc = accuracy(model, train_input, train_target, mini_batch_size)\n",
    "        test_acc = accuracy(model, test_input, test_target, mini_batch_size)\n",
    "        \n",
    "        if verbose:\n",
    "            print('Epoch {:d}: loss {:.3f} / train accuracy {:.1f}%, test accuracy {:.1f}'.format(\n",
    "                e, epoch_loss, train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 54.451 / train accuracy 81.4%, test accuracy 80.5\n",
      "Epoch 1: loss 36.914 / train accuracy 85.5%, test accuracy 81.2\n",
      "Epoch 2: loss 34.554 / train accuracy 83.5%, test accuracy 81.1\n",
      "Epoch 3: loss 31.035 / train accuracy 89.6%, test accuracy 84.4\n",
      "Epoch 4: loss 23.547 / train accuracy 87.7%, test accuracy 82.6\n",
      "Epoch 5: loss 21.905 / train accuracy 95.2%, test accuracy 82.8\n",
      "Epoch 6: loss 17.663 / train accuracy 95.7%, test accuracy 84.8\n",
      "Epoch 7: loss 14.333 / train accuracy 94.0%, test accuracy 83.8\n",
      "Epoch 8: loss 12.804 / train accuracy 96.2%, test accuracy 83.0\n",
      "Epoch 9: loss 9.355 / train accuracy 97.1%, test accuracy 84.2\n"
     ]
    }
   ],
   "source": [
    "model = Net(200, 10)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "eta = 1e-3\n",
    "mini_batch_size = 10\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = eta)\n",
    "nb_epochs = 10\n",
    "\n",
    "\n",
    "        \n",
    "train_model(model, train_input, train_target.float(), mini_batch_size, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 32855 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "nParams = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('The model has {:d} trainable parameters'.format(nParams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model(test_input)\n",
    "show_pair(test_input, predictions, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

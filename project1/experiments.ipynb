{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KFH2Hkok1-eP",
    "outputId": "f5758313-597d-4af2-f742-f6bc42b56393"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_input            1000 x 2 x 14 x 14   dtype               \n",
      "train_target                  1000          dtype               \n",
      "train_classes               1000 x 2        dtype               \n",
      "test_input             1000 x 2 x 14 x 14   dtype               \n",
      "test_target                   1000          dtype               \n",
      "test_classes                1000 x 2        dtype               \n"
     ]
    }
   ],
   "source": [
    "from dlc_practical_prologue import generate_pair_sets\n",
    "\n",
    "nSamples = 1000\n",
    "data = generate_pair_sets(nSamples)\n",
    "var_names = [\"train_input\", \"train_target\", \"train_classes\", \"test_input\", \"test_target\", \"test_classes\"]\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = data\n",
    "stringWidth = 20\n",
    "for i, el in enumerate(list(map(lambda x: (x.shape, x.dtype), data))):\n",
    "    print('{:s}  {:s}  {:s}'.format(\n",
    "        var_names[i].ljust(stringWidth),\n",
    "        ' x '.join(list(map(lambda x: str(x), list(el[0])))).center(stringWidth), \n",
    "        'dtype'.ljust(stringWidth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "2hJioqTe1-ei",
    "outputId": "5c54e86f-929d-4f91-d9ca-ba3c5e0d7858"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import show_pair\n",
    "\n",
    "show_pair(train_input, train_target, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2s1fno_F1-ej"
   },
   "source": [
    "## Without using the information from the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Zz45wRp1-ej",
    "outputId": "bb6abc35-3aa8-4585-e8ca-3b64b2f62b9a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/relja/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:145: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 9.317 / train accuracy 77.6%, test accuracy 76.3\n",
      "Epoch 1: loss 4.913 / train accuracy 81.3%, test accuracy 78.9\n",
      "Epoch 2: loss 4.256 / train accuracy 84.7%, test accuracy 80.3\n",
      "Epoch 3: loss 3.511 / train accuracy 86.5%, test accuracy 81.7\n",
      "Epoch 4: loss 3.208 / train accuracy 90.5%, test accuracy 83.1\n",
      "Epoch 5: loss 2.833 / train accuracy 89.0%, test accuracy 81.6\n",
      "Epoch 6: loss 2.741 / train accuracy 92.0%, test accuracy 83.0\n",
      "Epoch 7: loss 2.361 / train accuracy 93.7%, test accuracy 85.6\n",
      "Epoch 8: loss 1.992 / train accuracy 95.4%, test accuracy 84.0\n",
      "Epoch 9: loss 1.787 / train accuracy 94.8%, test accuracy 84.7\n"
     ]
    }
   ],
   "source": [
    "from utils import train_model\n",
    "from models.net1 import Net1\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model = Net1(50)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "eta = 1e-3\n",
    "mini_batch_size = 100\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = eta)\n",
    "nb_epochs = 10\n",
    "\n",
    "\n",
    "        \n",
    "train_model(model, train_input, train_target.float(), test_input, test_target, nb_epochs, mini_batch_size, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hkd0lSkC1-ek",
    "outputId": "c42a34ef-95a5-4bb3-d90c-22f3d03935a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 29789 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "nParams = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('The model has {:d} trainable parameters'.format(nParams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "yuZbYatM1-ek",
    "outputId": "862b1d5a-7a4c-401c-d779-904322e0c482"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model(test_input)\n",
    "show_pair(test_input, predictions, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhzU9IT31-el"
   },
   "source": [
    "## With class information during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z93tYxwS1-el",
    "outputId": "ea08738c-a1c1-4be7-d173-135d3cd38e40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 373.599 / train accuracy 75.7%, test accuracy 76.0\n",
      "Epoch 1: loss 142.541 / train accuracy 83.3%, test accuracy 82.4\n",
      "Epoch 2: loss 97.882 / train accuracy 87.0%, test accuracy 86.4\n",
      "Epoch 3: loss 75.319 / train accuracy 90.4%, test accuracy 86.9\n",
      "Epoch 4: loss 65.818 / train accuracy 90.6%, test accuracy 87.3\n",
      "Epoch 5: loss 50.576 / train accuracy 93.2%, test accuracy 89.4\n",
      "Epoch 6: loss 46.370 / train accuracy 92.1%, test accuracy 87.5\n",
      "Epoch 7: loss 44.755 / train accuracy 94.2%, test accuracy 89.3\n",
      "Epoch 8: loss 40.524 / train accuracy 94.4%, test accuracy 89.9\n",
      "Epoch 9: loss 31.748 / train accuracy 95.3%, test accuracy 89.8\n"
     ]
    }
   ],
   "source": [
    "from utils import train_model_double_objective\n",
    "from models.net2 import Net2\n",
    "\n",
    "model = Net2(50)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "eta = 1e-3\n",
    "mini_batch_size = 10\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = eta)\n",
    "nb_epochs = 10\n",
    "\n",
    "\n",
    "        \n",
    "train_model_double_objective(model, train_input, train_target.float(), \n",
    "                             train_classes, test_input, test_target, \n",
    "                             test_classes, nb_epochs, mini_batch_size, optimizer, \n",
    "                             criterion, criterion2, beta = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JE_of7dpB8e1",
    "outputId": "3ca660c1-9d10-4a6e-e46b-cf6732e2a91f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.70\n"
     ]
    }
   ],
   "source": [
    "from utils import accuracy_of_digit_class\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_of_digit_class(model, test_input, test_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained digit classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 32.280 / train accuracy 35.9%, test accuracy 28.8\n",
      "Epoch 1: loss 18.608 / train accuracy 60.7%, test accuracy 57.4\n",
      "Epoch 2: loss 13.218 / train accuracy 75.4%, test accuracy 69.0\n",
      "Epoch 3: loss 8.785 / train accuracy 85.3%, test accuracy 79.2\n",
      "Epoch 4: loss 5.846 / train accuracy 90.9%, test accuracy 85.0\n",
      "Epoch 5: loss 4.669 / train accuracy 91.9%, test accuracy 86.8\n",
      "Epoch 6: loss 4.086 / train accuracy 92.2%, test accuracy 87.8\n",
      "Epoch 7: loss 3.087 / train accuracy 95.2%, test accuracy 89.4\n",
      "Epoch 8: loss 2.218 / train accuracy 96.5%, test accuracy 90.8\n",
      "Epoch 9: loss 2.117 / train accuracy 97.2%, test accuracy 90.5\n",
      "Epoch 10: loss 1.741 / train accuracy 96.8%, test accuracy 89.3\n",
      "Epoch 11: loss 1.413 / train accuracy 98.6%, test accuracy 92.5\n",
      "Epoch 12: loss 1.281 / train accuracy 98.9%, test accuracy 91.1\n",
      "Epoch 13: loss 1.203 / train accuracy 99.1%, test accuracy 91.0\n",
      "Epoch 14: loss 0.875 / train accuracy 99.6%, test accuracy 91.0\n",
      "Epoch 15: loss 0.642 / train accuracy 99.8%, test accuracy 91.5\n",
      "Epoch 16: loss 0.672 / train accuracy 99.8%, test accuracy 91.4\n",
      "Epoch 17: loss 0.605 / train accuracy 99.8%, test accuracy 91.7\n",
      "Epoch 18: loss 0.536 / train accuracy 99.7%, test accuracy 92.2\n",
      "Epoch 19: loss 0.369 / train accuracy 99.8%, test accuracy 91.4\n"
     ]
    }
   ],
   "source": [
    "from models.digit_classifier import DigitClassifier\n",
    "import torch\n",
    "from torch import nn\n",
    "from utils import train_model\n",
    "\n",
    "mini_batch_size = 100\n",
    "model_classifier = DigitClassifier(out_h = 10, subnet = False)\n",
    "\n",
    "optimizer = torch.optim.Adam(model_classifier.parameters(), lr = 1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_in = train_input[:, 0, :, :].unsqueeze(axis = 1)\n",
    "train_class = train_classes[:,0]\n",
    "test_in = test_input[:, 0, :, :].unsqueeze(axis = 1)\n",
    "test_class = test_classes[:,0]\n",
    "\n",
    "train_model(model = model_classifier, \n",
    "            train_input = train_in, train_target = train_class,\n",
    "            test_input = test_in, test_target = test_class,\n",
    "            nb_epochs = 20, mini_batch_size = 100, \n",
    "            optimizer = optimizer, criterion = criterion,\n",
    "            verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 129.330 / train accuracy 86.2%, test accuracy 84.5\n",
      "Epoch 1: loss 75.703 / train accuracy 88.5%, test accuracy 85.6\n",
      "Epoch 2: loss 69.721 / train accuracy 91.1%, test accuracy 86.3\n",
      "Epoch 3: loss 51.596 / train accuracy 91.4%, test accuracy 86.9\n",
      "Epoch 4: loss 50.063 / train accuracy 91.3%, test accuracy 87.0\n",
      "Epoch 5: loss 46.944 / train accuracy 93.4%, test accuracy 89.0\n",
      "Epoch 6: loss 33.814 / train accuracy 95.2%, test accuracy 89.7\n",
      "Epoch 7: loss 28.713 / train accuracy 95.0%, test accuracy 87.6\n",
      "Epoch 8: loss 23.977 / train accuracy 96.2%, test accuracy 89.9\n",
      "Epoch 9: loss 28.660 / train accuracy 97.1%, test accuracy 90.0\n"
     ]
    }
   ],
   "source": [
    "from utils import train_model_double_objective\n",
    "from models.net4 import Net4\n",
    "\n",
    "model = Net4(model_classifier)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "eta = 1e-3\n",
    "mini_batch_size = 10\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = eta)\n",
    "nb_epochs = 10\n",
    "\n",
    "\n",
    "        \n",
    "train_model_double_objective(model, train_input, train_target.float(), \n",
    "                             train_classes, test_input, test_target, \n",
    "                             test_classes, nb_epochs, mini_batch_size, optimizer, \n",
    "                             criterion, criterion2, beta = 1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "experiments.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deb25d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "from models.digit_classifier import DigitClassifier\n",
    "from utils import accuracy\n",
    "from utils import train_model_double_objective\n",
    "from importlib import reload\n",
    "from models.net3 import Net3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ee9a140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlc_practical_prologue import generate_pair_sets\n",
    "\n",
    "nSamples = 1000\n",
    "data = generate_pair_sets(nSamples)\n",
    "var_names = [\"train_input\", \"train_target\", \"train_classes\", \"test_input\", \"test_target\", \"test_classes\"]\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = data\n",
    "stringWidth = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdcd6656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 34.228 / train accuracy 31.5%, test accuracy 27.6\n",
      "Epoch 1: loss 17.925 / train accuracy 61.6%, test accuracy 56.1\n",
      "Epoch 2: loss 12.680 / train accuracy 78.0%, test accuracy 73.3\n",
      "Epoch 3: loss 8.874 / train accuracy 87.3%, test accuracy 79.6\n",
      "Epoch 4: loss 5.958 / train accuracy 89.2%, test accuracy 82.8\n",
      "Epoch 5: loss 4.605 / train accuracy 92.3%, test accuracy 85.4\n",
      "Epoch 6: loss 3.657 / train accuracy 95.1%, test accuracy 90.1\n",
      "Epoch 7: loss 2.819 / train accuracy 95.0%, test accuracy 88.9\n",
      "Epoch 8: loss 2.832 / train accuracy 96.0%, test accuracy 90.9\n",
      "Epoch 9: loss 2.255 / train accuracy 96.7%, test accuracy 89.2\n",
      "Epoch 10: loss 1.865 / train accuracy 97.8%, test accuracy 90.4\n",
      "Epoch 11: loss 1.381 / train accuracy 98.1%, test accuracy 92.3\n",
      "Epoch 12: loss 1.047 / train accuracy 99.1%, test accuracy 92.2\n",
      "Epoch 13: loss 0.887 / train accuracy 98.9%, test accuracy 91.7\n",
      "Epoch 14: loss 0.690 / train accuracy 99.2%, test accuracy 92.6\n",
      "Epoch 15: loss 0.690 / train accuracy 99.6%, test accuracy 94.1\n",
      "Epoch 16: loss 0.618 / train accuracy 99.6%, test accuracy 93.4\n",
      "Epoch 17: loss 0.448 / train accuracy 99.9%, test accuracy 93.8\n",
      "Epoch 18: loss 0.521 / train accuracy 99.8%, test accuracy 93.3\n",
      "Epoch 19: loss 0.411 / train accuracy 99.8%, test accuracy 93.7\n"
     ]
    }
   ],
   "source": [
    "#pre-train model for classifying digits\n",
    "from models.digit_classifier import DigitClassifier\n",
    "import torch\n",
    "from torch import nn\n",
    "from utils import train_model\n",
    "\n",
    "mini_batch_size = 100\n",
    "model_classifier = DigitClassifier(out_h = 10, subnet = False)\n",
    "\n",
    "optimizer = torch.optim.Adam(model_classifier.parameters(), lr = 1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_in = train_input[:, 0, :, :].unsqueeze(axis = 1)\n",
    "train_class = train_classes[:,0]\n",
    "test_in = test_input[:, 0, :, :].unsqueeze(axis = 1)\n",
    "test_class = test_classes[:,0]\n",
    "\n",
    "train_model(model = model_classifier, \n",
    "            train_input = train_in, train_target = train_class,\n",
    "            test_input = test_in, test_target = test_class,\n",
    "            nb_epochs = 20, mini_batch_size = 100, \n",
    "            optimizer = optimizer, criterion = criterion,\n",
    "            verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88185f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss 16.714 / train accuracy 71.4%, test accuracy 71.7\n",
      "Epoch 1: loss 10.339 / train accuracy 76.8%, test accuracy 77.4\n",
      "Epoch 2: loss 8.614 / train accuracy 82.3%, test accuracy 80.9\n",
      "Epoch 3: loss 7.003 / train accuracy 85.0%, test accuracy 82.6\n",
      "Epoch 4: loss 6.509 / train accuracy 85.5%, test accuracy 83.7\n",
      "Epoch 5: loss 6.491 / train accuracy 88.8%, test accuracy 85.2\n",
      "Epoch 6: loss 5.715 / train accuracy 89.1%, test accuracy 85.9\n",
      "Epoch 7: loss 5.026 / train accuracy 91.0%, test accuracy 87.8\n",
      "Epoch 8: loss 4.072 / train accuracy 91.5%, test accuracy 87.8\n",
      "Epoch 9: loss 4.067 / train accuracy 92.6%, test accuracy 88.5\n"
     ]
    }
   ],
   "source": [
    "model = Net3(nb_residual_blocks = 20, pretrained_submodel = model_classifier, c1 = 32, c2 = 32, c3 = 64, h = 100, p = 0.3, hidden_channel_1 = 1, hidden_channel_2 = 10)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "eta = 1e-3\n",
    "mini_batch_size = 100\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = eta)\n",
    "nb_epochs = 10\n",
    "\n",
    "train_model_double_objective(model, train_input, train_target, \n",
    "                             train_classes, test_input, test_target, test_classes, \n",
    "                             nb_epochs, mini_batch_size, optimizer, criterion, criterion2, \n",
    "                             beta = 1, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "336af53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.50\n"
     ]
    }
   ],
   "source": [
    "from utils import accuracy_of_digit_class\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_of_digit_class(model, test_input, test_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "867f256c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 29605 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "nParams = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('The model has {:d} trainable parameters'.format(nParams))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
